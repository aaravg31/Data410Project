{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "539fc34b-46aa-4cca-8abc-051d83db061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw as praw\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import emoji\n",
    "import spacy\n",
    "from better_profanity import profanity\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "459d1f4b-fe9e-4eaf-afaa-d65e7a05bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "profanity.load_censor_words()\n",
    "def is_question_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return 1 if any(token.dep_ == \"aux\" and token.head.pos_ == \"VERB\" for token in doc) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3944c42a-5283-47de-aefc-1f980b515581",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id= credential.REDDIT_CLIENT_ID,  \n",
    "    client_secret= credential.REDDIT_CLIENT_SECRET,  \n",
    "    user_agent= credential.REDDIT_USER_AGENT\n",
    ")\n",
    "\n",
    "reddit.read_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1791582a-cbb6-4037-b87b-889e532b929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_name = \"datascience\"\n",
    "sort_by = \"hot\"  # Options: 'hot', 'new', 'top', 'rising'\n",
    "num_posts = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4b156fbe-6f6f-4e1f-b8c2-77a2b82dfc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/77/v3y346fs73v85gq618945pxr0000gn/T/ipykernel_7427/101886555.py:38: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  account_age = (datetime.datetime.utcnow() - datetime.datetime.utcfromtimestamp(comment.author.created_utc)).days\n",
      "/var/folders/77/v3y346fs73v85gq618945pxr0000gn/T/ipykernel_7427/101886555.py:38: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  account_age = (datetime.datetime.utcnow() - datetime.datetime.utcfromtimestamp(comment.author.created_utc)).days\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "subreddit = reddit.subreddit(subreddit_name)\n",
    "posts = getattr(subreddit, sort_by)(limit=num_posts)\n",
    "\n",
    "for post in posts:\n",
    "    submission = reddit.submission(id=post.id)\n",
    "    submission.comments.replace_more(limit=5)  # Limit deep threading\n",
    "\n",
    "    # Get post creation time in UTC\n",
    "    post_time_utc = datetime.datetime.fromtimestamp(submission.created_utc, datetime.UTC)\n",
    "\n",
    "    for comment in submission.comments.list():\n",
    "        # Text features\n",
    "        text = comment.body\n",
    "        sentiment_score = analyzer.polarity_scores(text)[\"compound\"]\n",
    "        text_length = len(text)\n",
    "        num_words = len(text.split())\n",
    "        contains_question = is_question_spacy(text)\n",
    "        contains_emoji = 1 if any(emoji.is_emoji(char) for char in text) else 0\n",
    "        contains_profanity = 1 if profanity.contains_profanity(text) else 0\n",
    "\n",
    "        # Metadata features\n",
    "        comment_time_utc = datetime.datetime.fromtimestamp(comment.created_utc, datetime.UTC)\n",
    "        comment_age_hours = (comment_time_utc - post_time_utc).total_seconds() / 3600\n",
    "        is_early_comment = 1 if comment_age_hours <= 1 else 0  # Early = within 1 hour\n",
    "\n",
    "        comment_hour = comment_time_utc.hour\n",
    "        comment_day = comment_time_utc.weekday()\n",
    "        subreddit_name = submission.subreddit.display_name\n",
    "        parent_score = comment.parent().score if comment.parent_id != submission.id else None\n",
    "\n",
    "        # User-based features\n",
    "        user_karma = None\n",
    "        account_age = None\n",
    "        \n",
    "        if comment.author:\n",
    "            user_karma = comment.author.comment_karma\n",
    "            account_age = (datetime.datetime.utcnow() - datetime.datetime.utcfromtimestamp(comment.author.created_utc)).days\n",
    "\n",
    "        # Engagement variables (dependent variables)\n",
    "        comment_score = comment.score\n",
    "        num_replies = len(comment.replies)\n",
    "\n",
    "        # Store data\n",
    "        data.append({\n",
    "            \"Comment Score\": comment_score,\n",
    "            \"Number of Replies\": num_replies,\n",
    "            \"Text\" : text,\n",
    "            \"Sentiment Score\": sentiment_score,\n",
    "            \"Text Length\": text_length,\n",
    "            \"Word Count\": num_words,\n",
    "            \"Contains Question\": contains_question,\n",
    "            \"Contains Emoji\": contains_emoji,\n",
    "            \"Contains Profanity\": contains_profanity,\n",
    "            \"Comment Age (hours)\": comment_age_hours,\n",
    "            \"Comment Hour\": comment_hour,\n",
    "            \"Comment Day\": comment_day,\n",
    "            \"Subreddit Name\": subreddit_name,\n",
    "            \"Is Early Comment\": is_early_comment,\n",
    "            \"Parent Score\": parent_score,\n",
    "            \"User Karma\": user_karma,\n",
    "            \"Account Age (days)\": account_age,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "12dfed9b-7787-4972-85ee-0b1260641786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b06600dc-9387-4355-8fa9-fe6b2e7ecdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 192 new rows checked. Unique dataset saved to 'reddit_engagement_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"reddit_engagement_data.csv\"\n",
    "\n",
    "if os.path.exists(csv_file):\n",
    "    df_existing = pd.read_csv(csv_file)\n",
    "    df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "    \n",
    "    # Remove duplicate rows\n",
    "    df_combined.drop_duplicates(inplace=True)\n",
    "    df_combined.to_csv(csv_file, index=False)\n",
    "    print(f\"✅ {len(df_new)} new rows checked. Unique dataset saved to '{csv_file}'.\")\n",
    "\n",
    "else:\n",
    "    df_new.to_csv(csv_file, index=False)\n",
    "    print(f\"✅ First-time save: {len(df_new)} rows saved to '{csv_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "210101e6-2f44-42ad-a9a6-92048629f2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_existing = pd.read_csv(\"reddit_engagement_data.csv\")\n",
    "len(df_existing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
