{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539fc34b-46aa-4cca-8abc-051d83db061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw as praw\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import emoji\n",
    "import spacy\n",
    "from better_profanity import profanity\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import credential\n",
    "import time\n",
    "from prawcore.exceptions import TooManyRequests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459d1f4b-fe9e-4eaf-afaa-d65e7a05bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "profanity.load_censor_words()\n",
    "\n",
    "def is_question_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return 1 if any(token.dep_ == \"aux\" and token.head.pos_ == \"VERB\" for token in doc) else 0\n",
    "\n",
    "def get_user_data(author):\n",
    "    if not author:\n",
    "        return None, None, 0  # No author data\n",
    "\n",
    "    try:\n",
    "        user_karma = author.comment_karma\n",
    "        account_age = (datetime.datetime.now(datetime.UTC) - datetime.datetime.fromtimestamp(author.created_utc, datetime.UTC)).days\n",
    "        has_flair = 1 if author.has_verified_email else 0\n",
    "        return user_karma, account_age, has_flair\n",
    "    except TooManyRequests:\n",
    "        print(\"⚠️ Rate limit hit! Sleeping for 15 seconds...\")\n",
    "        time.sleep(15)  # Wait 15 seconds if rate limit is hit\n",
    "        return None, None, 0\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to fetch user data: {e}\")\n",
    "        return None, None, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3944c42a-5283-47de-aefc-1f980b515581",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id= credential.REDDIT_CLIENT_ID,  \n",
    "    client_secret= credential.REDDIT_CLIENT_SECRET,  \n",
    "    user_agent= credential.REDDIT_USER_AGENT\n",
    ")\n",
    "\n",
    "reddit.read_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1791582a-cbb6-4037-b87b-889e532b929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_name = \"AskReddit\"\n",
    "sort_by = \"hot\"  # Options: 'hot', 'new', 'top', 'rising'\n",
    "num_posts = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b156fbe-6f6f-4e1f-b8c2-77a2b82dfc8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Rate limit hit! Sleeping for 15 seconds...\n",
      "⚠️ Failed to fetch user data: 'Redditor' object has no attribute 'comment_karma'\n",
      "⚠️ Rate limit hit! Sleeping for 15 seconds...\n",
      "⚠️ Failed to fetch user data: 'Redditor' object has no attribute 'comment_karma'\n",
      "⚠️ Rate limit hit! Sleeping for 15 seconds...\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "subreddit = reddit.subreddit(subreddit_name)\n",
    "posts = getattr(subreddit, sort_by)(limit=num_posts)\n",
    "\n",
    "for post in posts:\n",
    "    submission = reddit.submission(id=post.id)\n",
    "    submission.comments.replace_more(limit=1)  # Limit deep threading\n",
    "\n",
    "    # Get post creation time in UTC\n",
    "    post_time_utc = datetime.datetime.fromtimestamp(submission.created_utc, datetime.UTC)\n",
    "\n",
    "    for comment in submission.comments.list():\n",
    "        # Text features\n",
    "        text = comment.body\n",
    "        sentiment_score = analyzer.polarity_scores(text)[\"compound\"]\n",
    "        text_length = len(text)\n",
    "        num_words = len(text.split())\n",
    "        contains_question = is_question_spacy(text)\n",
    "        contains_emoji = 1 if any(emoji.is_emoji(char) for char in text) else 0\n",
    "        contains_profanity = 1 if profanity.contains_profanity(text) else 0\n",
    "\n",
    "        # Metadata features\n",
    "        comment_time_utc = datetime.datetime.fromtimestamp(comment.created_utc, datetime.UTC)\n",
    "        comment_age_hours = (comment_time_utc - post_time_utc).total_seconds() / 3600\n",
    "        is_early_comment = 1 if comment_age_hours <= 1 else 0  # Early = within 1 hour\n",
    "\n",
    "        comment_hour = comment_time_utc.hour\n",
    "        comment_day = comment_time_utc.weekday()\n",
    "        subreddit_name = submission.subreddit.display_name\n",
    "        parent_score = comment.parent().score if comment.parent_id != submission.id else None\n",
    "\n",
    "        # User-based features\n",
    "        user_karma, account_age, has_flair = get_user_data(comment.author)\n",
    "\n",
    "        # Engagement variables (dependent variables)\n",
    "        comment_score = comment.score\n",
    "        num_replies = len(comment.replies)\n",
    "\n",
    "        # Store data\n",
    "        data.append({\n",
    "            \"Comment Score\": comment_score,\n",
    "            \"Number of Replies\": num_replies,\n",
    "            \"Text\" : text,\n",
    "            \"Subreddit Name\": subreddit_name,\n",
    "            \"Sentiment Score\": sentiment_score,\n",
    "            \"Text Length\": text_length,\n",
    "            \"Word Count\": num_words,\n",
    "            \"Contains Question\": contains_question,\n",
    "            \"Contains Emoji\": contains_emoji,\n",
    "            \"Contains Profanity\": contains_profanity,\n",
    "            \"Comment Age (hours)\": comment_age_hours,\n",
    "            \"Comment Hour\": comment_hour,\n",
    "            \"Comment Day\": comment_day,\n",
    "            \"Is Early Comment\": is_early_comment,\n",
    "            \"Parent Score\": parent_score,\n",
    "            \"User Karma\": user_karma,\n",
    "            \"Account Age (days)\": account_age,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12dfed9b-7787-4972-85ee-0b1260641786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b06600dc-9387-4355-8fa9-fe6b2e7ecdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 5801 new rows checked. Unique dataset saved to 'reddit_engagement_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"reddit_engagement_data.csv\"\n",
    "\n",
    "if os.path.exists(csv_file):\n",
    "    df_existing = pd.read_csv(csv_file)\n",
    "    df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "    \n",
    "    # Remove duplicate rows\n",
    "    df_combined = df_combined.drop_duplicates(subset=[\"Text\", \"Subreddit Name\"], keep=\"first\")\n",
    "    df_combined.to_csv(csv_file, index=False)\n",
    "    print(f\"✅ {len(df_new)} new rows checked. Unique dataset saved to '{csv_file}'.\")\n",
    "\n",
    "else:\n",
    "    df_new.to_csv(csv_file, index=False)\n",
    "    print(f\"✅ First-time save: {len(df_new)} rows saved to '{csv_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bef9f97-f94b-4c31-98d3-c44810457136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
